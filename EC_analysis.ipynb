{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b9ce52",
   "metadata": {},
   "source": [
    "# EC analysis\n",
    "#### This script aims to analyse IF slides with the following content:\n",
    "- 405: DAPI\n",
    "- 488: macs\n",
    "- 594: cTnT\n",
    "- 647: EC\n",
    "\n",
    "#### Following input is required:\n",
    "- Separate images of the channels with *.tif* file format saved in one folder. If the images in the folder do not share the same pixel size, it should be specified in their name (e.g. Imagename_20x_ch00.tif). This script calculates the areas in um^2/nuclei, which makes this especially important to the user, as it could cause significant miscalculations in the results. Note that areas of the organoid/epicardium/myocardium are saved both in px and in um^2, which can serve as a user control. Default pixel size can be specified in the 'PARAMETERS' section. The default will be used for all images where it is not specified otherwise.\n",
    "\n",
    "- Nuclei masks with the following naming format: 'Imagename_{suffix}' for all images, saved in a single folder. Separate script was created containing cellpose machine learning model to create the mask separately. Path to the nuclei masks can be specified under 'folder2' variable.\n",
    "\n",
    "- Average macrophage size estimate in um. The macrophage sizes tend to be quite variable. For the randomised control of distances to be measured as accurately as possible, the average size of macrophage in the real data has to be measured prior to running the script.\n",
    "\n",
    "- Area around EC that should be searched for macrophage in um. Note that the larger the area is, the longer the script will run the calculations. This is one of the most time-consuming parts of the script.\n",
    "\n",
    "#### Process:\n",
    "The script exctracts the individual channel images and puts them into a dictionary keyed under their names. \n",
    "In 'PARAMETERS testing' section of this script there are defined functions that determine the signal areas in each individual image. These functions can be adjusted for each individual dataset.\n",
    "Then the script goes through all the images individually. Epicardium/myocardium area is determined based on the cTnT staining and is used to analyse mac/EC areas and distributions. The script also calculates area and sphericity of each individual EC object and whether it: a) has macrophage within 30um distance, b) how far the macrophage is from EC, c) how many different macrophages are within the specified area. This is done for both real data and a randomised macrophage data (macrophage-approximations ~ circles with the same area as real macrophages, that are placed randomly in the organoid).\n",
    "\n",
    "#### Output:\n",
    "- The script generates masks for each image and saves them as .tif.\n",
    "- The script saves all the data into 2 separate excel sheets. One contains the area/localisation data for each image. The second contains data for each individual EC object separately (i.e. areas, distances, number of macs, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd42c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIBRARY\n",
    "import os\n",
    "import glob\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_minimum, threshold_isodata, threshold_triangle, threshold_mean\n",
    "from skimage.filters import threshold_otsu, threshold_li, threshold_yen\n",
    "from skimage.morphology import binary_dilation\n",
    "from scipy.ndimage import binary_erosion\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.filters import gaussian\n",
    "from skimage.morphology import label\n",
    "from skimage.measure import regionprops\n",
    "from skimage.morphology import remove_small_objects\n",
    "from skimage.morphology import remove_small_holes\n",
    "from skimage.morphology import disk\n",
    "from statistics import mean, stdev\n",
    "from natsort import natsorted\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "## addition for distances:\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage import measure\n",
    "from skimage.segmentation import find_boundaries\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241db160",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "### PARAMETERS\n",
    "filename = ''\n",
    "\n",
    "default_pixel_size = 0.65\n",
    "print(f'Currently used pixel size is: {default_pixel_size}')\n",
    "\n",
    "# filename extract\n",
    "last_folder = os.path.basename(filename)\n",
    "# output folder:\n",
    "output_folder = ''\n",
    "\n",
    "# to save masks:\n",
    "folder1 = f'{filename}/masks_with_nuclei_count'  # here is where the images of the masks get saved\n",
    "folder2 = f'{filename}/masks_nuclei' # here is the path to nuclei masks\n",
    "os.makedirs(folder1, exist_ok=True)\n",
    "os.makedirs(folder2, exist_ok=True)\n",
    "\n",
    "print(last_folder)\n",
    "\n",
    "# to correctly extract the channels:\n",
    "nuclei_mask_suffix = '_ch00_mask.tif'\n",
    "ch405_suffix = '_ch00.tif'\n",
    "ch488_suffix = '_ch01.tif'\n",
    "ch594_suffix = '_ch02.tif'\n",
    "ch647_suffix = '_ch03.tif'\n",
    "\n",
    "# to correctly calculate the area:\n",
    "pixel_size_5x = 1.3\n",
    "pixel_size_10x = 0.65\n",
    "pixel_size_20x = 0.325\n",
    "pixel_size_40x = 0.1625\n",
    "pixel_size_63x = 0.103125\n",
    "\n",
    "# to correctly calculate mac sizes for the distances and random distribution:\n",
    "estimated_mac_radius = 8 #in um (originally about 6.5 for EXP6/EXP7)\n",
    "measured_dist_around_EC = 29.9 #in um (for the distances calculation - how far from the EC does mac count as relevant)\n",
    "estimated_mac_area = math.pi*(estimated_mac_radius**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b05c98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOADING IMAGES\n",
    "\n",
    "## DAPI in 405 channel:\n",
    "list_of_dapi_files = natsorted(glob.glob(f\"{filename}/{ch405_suffix}.tif\"))\n",
    "images_dapi = {}\n",
    "images_dapi_list = []\n",
    "for file in list_of_dapi_files:\n",
    "    img = io.imread(file)\n",
    "    images_dapi[os.path.basename(file)] = img\n",
    "    images_dapi_list.append(img)\n",
    "\n",
    "## 488 channel:\n",
    "list_of_488_files = natsorted(glob.glob(f\"{filename}/{ch488_suffix}.tif\"))\n",
    "images_488 = {}\n",
    "for file in list_of_488_files:\n",
    "    img = io.imread(file)\n",
    "    images_488[os.path.basename(file)] = img\n",
    "\n",
    "## 594 channel:\n",
    "list_of_594_files = natsorted(glob.glob(f\"{filename}/{ch594_suffix}.tif\"))\n",
    "images_594 = {}\n",
    "for file in list_of_594_files:\n",
    "    img = io.imread(file)\n",
    "    images_594[os.path.basename(file)] = img\n",
    "\n",
    "## 647 channel:\n",
    "list_of_647_files = natsorted(glob.glob(f\"{filename}/{ch647_suffix}.tif\"))\n",
    "images_647 = {}\n",
    "for file in list_of_647_files:\n",
    "    img = io.imread(file)\n",
    "    images_647[os.path.basename(file)] = img\n",
    "\n",
    "print(f\"to check: \\n number of 405 images: \\t {len(images_dapi)}, \\n number of 488 images: \\t {len(images_488)},\"\n",
    "      f\"\\n number of 594 images: \\t {len(images_594)}, \\n number of 647 images: \\t {len(images_647)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0e1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Grabbing the cellpose masks from the folder\n",
    "\n",
    "list_of_nuclei_mask_files = natsorted(glob.glob(f\"{folder2}/*.tif\"))\n",
    "nuclei_masks = {}\n",
    "\n",
    "for file in list_of_nuclei_mask_files:\n",
    "    img = io.imread(file)\n",
    "    nuclei_masks[os.path.basename(file)] = img\n",
    "\n",
    "print(f'Number of nuclei masks: {len(nuclei_masks)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e07b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAMETERS testing\n",
    "\n",
    "tested_image = 'Series001_ICC' #'Image 1'\n",
    "\n",
    "def dapi_analysis(mask):\n",
    "    thresholding = mask > threshold_triangle(mask)\n",
    "    dilated = binary_dilation(thresholding, iterations=100) #dilates the individual nuclei by 100 pixels\n",
    "                                                            #merges the signal together\n",
    "    thresholding_2 = remove_small_holes(dilated, area_threshold=10000)\n",
    "    eroded = binary_erosion(thresholding_2, iterations=80) #erodes the expanded mask back to original size\n",
    "                                                           # ~20px smaller than dilation, because the real  \n",
    "                                                           #organoid is a bit larger than just nuclei mask\n",
    "    thresholding_3 = remove_small_objects(eroded, min_size=8000) #removes stray nuclei outside of the organoid\n",
    "    blurred = gaussian(thresholding_3, sigma=10) #blurrs the jagged edges\n",
    "    smoothed = blurred > 0.2 #blurring makes the image non-binary, this makes it binary again by selecting\n",
    "                             #the intensities over certain threshold (in this case everything over 20%)\n",
    "    return(smoothed)\n",
    "\n",
    "## 488\n",
    "def analysis_488(image):\n",
    "    thresholding_1 = image > threshold_triangle(image) #tresholding_otsu usually also works\n",
    "    thresholding_2 = remove_small_objects(thresholding_1, min_size=200) \n",
    "    return(thresholding_2)\n",
    "\n",
    "## 594\n",
    "def analysis_594(image):\n",
    "    blurring = gaussian(image,sigma=10) #blurred, because the channel has a lot of debri/unclear signal\n",
    "                                        #this pools the signal together/removes some of the background\n",
    "    thresholding = blurring > threshold_li(blurring)\n",
    "    thresholding_1 = remove_small_objects(thresholding, min_size=5000)\n",
    "    dilated = binary_dilation(thresholding_1, iterations=60)\n",
    "    thresholding_2 = remove_small_holes(dilated, area_threshold=1000000)\n",
    "    eroded = binary_erosion(thresholding_2, iterations=60)\n",
    "    thresholding_3 = remove_small_objects(eroded, min_size=15000)\n",
    "    return(thresholding_3)\n",
    "\n",
    "## 647\n",
    "def analysis_647(image):\n",
    "    normalisation = equalize_adapthist(image, clip_limit=0.004) #0.009\n",
    "    thresholding_1 = normalisation > threshold_triangle(normalisation) #NOTE: using a specific threshold \n",
    "                                                                       #value is usually fastest for individual images\n",
    "    thresholding_2 = remove_small_objects(thresholding_1, min_size=150)\n",
    "    return(thresholding_2)\n",
    "\n",
    "\n",
    "### Implementation to actual data:\n",
    "\n",
    "image_dapi_test = nuclei_masks[f'{tested_image}{nuclei_mask_suffix}'] #_ch00.tif_mask.tif\n",
    "image_thresholded = dapi_analysis(image_dapi_test)\n",
    "\n",
    "image_488_test = images_488[f'{tested_image}{ch488_suffix}']\n",
    "thresholded_488_test = analysis_488(image_488_test)\n",
    "\n",
    "image_594_test = images_594[f'{tested_image}{ch594_suffix}']\n",
    "thresholded_594_test = analysis_594(image_594_test)\n",
    "\n",
    "image_647_test = images_647[f'{tested_image}{ch647_suffix}']\n",
    "thresholded_647_test = analysis_647(image_647_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=2, ncols=3, figsize=(16,7))\n",
    "axs[0,0].imshow(image_dapi_test, cmap='viridis', vmin=0, vmax=15)\n",
    "axs[0,1].imshow(image_thresholded)\n",
    "axs[1,0].imshow(thresholded_488_test)\n",
    "axs[1,1].imshow(thresholded_594_test)\n",
    "axs[1,2].imshow(thresholded_647_test)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "# Show background image\n",
    "ax.imshow(image_thresholded, cmap='gray')\n",
    "# Nuclei\n",
    "ax.imshow(np.ma.masked_where(image_dapi_test == 0, image_dapi_test), cmap='Spectral', vmin=0, vmax=1, alpha=0.8)\n",
    "# macrophages\n",
    "ax.imshow(np.ma.masked_where(thresholded_488_test == 0, thresholded_488_test), cmap='Greens', vmin=0, vmax=1, alpha=0.9)\n",
    "# myocardium\n",
    "ax.imshow(np.ma.masked_where(thresholded_594_test == 0, thresholded_594_test), cmap='magma', alpha=0.4)\n",
    "# EC\n",
    "ax.imshow(np.ma.masked_where(thresholded_647_test == 0, thresholded_647_test), cmap=\"Wistia_r\", alpha=1) #vmin=low, vmax=high\n",
    "\n",
    "# ## testing of thresholding:\n",
    "# # tries all automatic thresholding options for the image \n",
    "# fig, ax = try_all_threshold(image_647_test, figsize=(6, 12), verbose=False)\n",
    "# plt.show()\n",
    "\n",
    "# # OLD script to show cTnT overlay in red\n",
    "# # from matplotlib.colors import LinearSegmentedColormap\n",
    "# # red_black = LinearSegmentedColormap.from_list(\"red_black\", [\"black\", \"red\"])\n",
    "# # ax.imshow(np.ma.masked_where(image_594_test == 0, image_594_test), cmap=red_black, vmin=150, vmax=250, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b2fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Distances functions\n",
    "\n",
    "def watershed_488(mask, pixel_size): # this helps approximate number of macrophages in a slice when they are clustered together\n",
    "    distance_transform_488 = ndi.distance_transform_edt(mask)\n",
    "    # Find peaks (likely centers of individual cells)\n",
    "    local_maxi_test = peak_local_max(distance_transform_488, labels=mask, footprint=np.ones((3, 3)), min_distance=int(19.5/pixel_size))\n",
    "    local_maxi_test_2 = np.zeros_like(distance_transform_488, dtype=bool)\n",
    "    local_maxi_test_2[tuple(local_maxi_test.T)] = True\n",
    "    # Label the peaks\n",
    "    markers = measure.label(local_maxi_test_2)\n",
    "    # watershed\n",
    "    watershed_labels_test = watershed(-distance_transform_488, markers, mask=mask)\n",
    "    return(watershed_labels_test)\n",
    "\n",
    "## fake 488 mask\n",
    "def fake_mac_analysis(organoid_area, mac_number, mac_size):\n",
    "    # this determines where the pixels are positive in the dapi mask:\n",
    "    organoid_coords = np.column_stack(np.where(organoid_area))\n",
    "    # this selects random coordinates inside the positive area of the dapi mask that is equal to the number \n",
    "    # of macs detected (approximated since the macs are basically a single mass and not individual cells)\n",
    "    select_indeces = np.random.choice(len(organoid_coords), size=mac_number, replace=False)\n",
    "    selected_coords = organoid_coords[select_indeces]\n",
    "    # new 'fake' mac mask:\n",
    "    seed_mask = np.zeros_like(organoid_area, dtype=bool)\n",
    "    seed_mask[selected_coords[:,0], selected_coords[:,1]] = 1\n",
    "    dilated = binary_dilation(seed_mask, disk(mac_size))\n",
    "    fake_mac_mask = np.logical_and(dilated, organoid_area)\n",
    "\n",
    "    return(fake_mac_mask)\n",
    "\n",
    "# to check average mac size:\n",
    "# image_488_test = images_488[f'{tested_image}{ch488_suffix}']\n",
    "# thresholded_488_test = analysis_488(image_488_test)\n",
    "# dist_test_488 = watershed_488(thresholded_488_test)\n",
    "# objects_488_test = regionprops(dist_test_488)\n",
    "# mean_areas_test = [obj.area for obj in objects_488_test]\n",
    "# print(f'this is the estimated mac area: {estimated_mac_area}')\n",
    "# print(f'this is the measured mac area: {mean(mean_areas_test)*(pixel_size**2)}') # average mac area from the image mask (271um^2 for d1_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b6c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Analysis\n",
    "Image_data_EC_files = {}\n",
    "Individual_data_EC_files = {}\n",
    "\n",
    "\n",
    "for name,img in images_dapi.items():\n",
    "\n",
    "    #image name extracted:\n",
    "    name_without_last_part = '_'.join(name.split('_')[:-1]) # splits the ch__ from the name, so that\n",
    "                                                              # the script can get the relevant images \n",
    "                                                              # from other channels\n",
    "\n",
    "    # pixel size extracted from 'name' (if available, otherwise default pixel size is used)\n",
    "    pixel_size = default_pixel_size\n",
    "    \n",
    "    if '5x' in name:\n",
    "        pixel_size = pixel_size_5x\n",
    "    elif '10x' in name:\n",
    "        pixel_size = pixel_size_10x\n",
    "    elif '20x' in name:\n",
    "        pixel_size = pixel_size_20x\n",
    "    elif '40x' in name:\n",
    "        pixel_size = pixel_size_40x\n",
    "    elif '63x' in name:\n",
    "        pixel_size = pixel_size_63x\n",
    "\n",
    "    mac_rad = round(estimated_mac_radius/pixel_size) # approximation of macrophage size\n",
    "\n",
    "    number_of_iter = round(29.9/pixel_size) # the recorded distance around EC (46 iter for 10x objective)\n",
    "\n",
    "\n",
    "    ### Creation of masks for the individual channels in the image:   \n",
    "                                                 \n",
    "    ## 405 (DAPI)\n",
    "    mask_405 = nuclei_masks[f'{name_without_last_part}{nuclei_mask_suffix}'] #_ch00.tif_mask.tif\n",
    "    thresholded_405 = dapi_analysis(mask_405) # organoid mask by blurring nuclei together\n",
    "    nuclei_objects = regionprops(mask_405, img)\n",
    "    ## 488 (macs)\n",
    "    img_488 = images_488[f'{name_without_last_part}{ch488_suffix}']\n",
    "    thresholded_488 = analysis_488(img_488) & thresholded_405 #only signal overlapping with organoid mask is captured\n",
    "    ## 594 (cTnT)\n",
    "    img_594 = images_594[f'{name_without_last_part}{ch594_suffix}']\n",
    "    myocardium = analysis_594(img_594) & thresholded_405\n",
    "    ## 647 (EC)\n",
    "    img_647 = images_647[f'{name_without_last_part}{ch647_suffix}']\n",
    "    thresholded_647 = analysis_647(img_647) & thresholded_405\n",
    "\n",
    "\n",
    "    ### Calculations:\n",
    "    \n",
    "    #DAPI signal/organoid size\n",
    "    organoid_size = np.sum(thresholded_405) #sum of all pixels, area in pixels^2\n",
    "    organoid_size_in_um = organoid_size*(pixel_size**2) #area in um^2\n",
    "    number_of_nuclei = mask_405.max() #number of nuclei detected by cellpose\n",
    "\n",
    "    # GFP signal/mac area\n",
    "    overal_488_signal = np.sum(thresholded_488) #sum of all pixels, area in pixels^2\n",
    "    mac_signal_in_um = overal_488_signal*(pixel_size**2)\n",
    "\n",
    "    # 594 signal/cTnT area\n",
    "    myocardium_area = np.sum(myocardium)\n",
    "    myocardium_area_in_um = myocardium_area*(pixel_size**2)\n",
    "    cTnT_per = myocardium_area/organoid_size\n",
    "\n",
    "    epicardium = thresholded_405 & (~myocardium)\n",
    "    epicardium_size = np.sum(epicardium)\n",
    "    epicardium_size_in_um = epicardium_size*(pixel_size**2)\n",
    "    epicardium_area_per = epicardium_size/organoid_size\n",
    "\n",
    "    #number of nuclei in myocardium:\n",
    "    nuclei_count_myo = 0\n",
    "    nuclei_count_epi = 0\n",
    "\n",
    "    nuclei_sizes_in_um = []\n",
    "\n",
    "    for obj in nuclei_objects:\n",
    "        coordinates = obj.coords\n",
    "        nucleus_area = obj.area\n",
    "        nuclei_sizes_in_um.append(nucleus_area*(pixel_size**2))\n",
    "\n",
    "        # nuclei in myocardium\n",
    "        overlap_myo = np.sum(myocardium[coordinates[:,0], coordinates[:,1]])\n",
    "        overlap_myo_per = overlap_myo/nucleus_area\n",
    "        # nuclei in epicardium\n",
    "        overlap_epi = np.sum(epicardium[coordinates[:,0], coordinates[:,1]])\n",
    "        overlap_epi_per = overlap_epi/nucleus_area\n",
    "\n",
    "        if overlap_myo_per > 0.5:\n",
    "            nuclei_count_myo += 1\n",
    "\n",
    "        if overlap_epi_per > 0.5:\n",
    "            nuclei_count_epi += 1\n",
    "\n",
    "\n",
    "    if nuclei_count_epi ==0:\n",
    "        print(f\"There is no epicardium in: {name_without_last_part}\")\n",
    "\n",
    "    if (nuclei_count_epi+nuclei_count_myo) != number_of_nuclei:\n",
    "        print(f\"{number_of_nuclei-(nuclei_count_epi+nuclei_count_myo)} nuclei are outside of measurement area in: {name_without_last_part}\")\n",
    "\n",
    "\n",
    "    # 647 signal/EC area\n",
    "    overal_647_signal = np.sum(thresholded_647)\n",
    "    EC_signal_in_um = overal_647_signal*(pixel_size**2)\n",
    "    EC_area_per = overal_647_signal/organoid_size\n",
    "    EC_area_per_nuclei = EC_signal_in_um/number_of_nuclei\n",
    "\n",
    "    macs_area_per = overal_488_signal/organoid_size\n",
    "    macs_area_per_nuclei = mac_signal_in_um/number_of_nuclei\n",
    "    \n",
    "\n",
    "    ## are ECs in epicardium or myocardium?\n",
    "\n",
    "    # area of signal per number of nuclei in epi/myo\n",
    "    EC_in_epi = thresholded_647 & epicardium #this is an array\n",
    "    EC_in_epi_um = np.sum(EC_in_epi)*(pixel_size**2) #this is pixel area converted to um^2\n",
    "    # np.divide to prevent division by 0\n",
    "    EC_in_epi_per_nuclei = float(np.divide(EC_in_epi_um, nuclei_count_epi, out=np.zeros_like(EC_in_epi_um), where=nuclei_count_epi!=0))\n",
    "    EC_per_in_epicardium = (np.sum(EC_in_epi) / overal_647_signal if overal_647_signal > 0 else 0.0)\n",
    "\n",
    "    EC_in_myo = thresholded_647 & myocardium\n",
    "    EC_in_myo_um = np.sum(EC_in_myo)*(pixel_size**2)\n",
    "    EC_in_myo_per_nuclei = float(np.divide(EC_in_myo_um, nuclei_count_myo, out=np.zeros_like(EC_in_myo_um), where=nuclei_count_myo!=0))\n",
    "    EC_per_in_myocardium = (np.sum(EC_in_myo) / overal_647_signal if overal_647_signal > 0 else 0.0)\n",
    "\n",
    "\n",
    "    ## are GFP+ in epicardium or myocardium?\n",
    "    GFP_in_epi = thresholded_488 & epicardium\n",
    "    GFP_in_epi_um = np.sum(GFP_in_epi)*(pixel_size**2)\n",
    "    GFP_in_epi_per_nuclei = float(np.divide(GFP_in_epi_um, nuclei_count_epi, out=np.zeros_like(GFP_in_epi_um), where=nuclei_count_epi!=0))\n",
    "    GFP_per_in_epicardium = np.sum(GFP_in_epi)/overal_488_signal\n",
    "\n",
    "    GFP_in_myo = thresholded_488 & myocardium\n",
    "    GFP_in_myo_um = np.sum(GFP_in_myo)*(pixel_size**2)\n",
    "    GFP_in_myo_per_nuclei = float(np.divide(GFP_in_myo_um, nuclei_count_myo, out=np.zeros_like(GFP_in_myo_um), where=nuclei_count_myo!=0))\n",
    "    GFP_per_in_myocardium = np.sum(GFP_in_myo)/overal_488_signal\n",
    "\n",
    "    #miscelaneous:\n",
    "    per_of_myo_nuclei = nuclei_count_myo/number_of_nuclei\n",
    "    per_of_epi_nuclei = nuclei_count_epi/number_of_nuclei\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ### Distances:\n",
    "    # this part searches the radius of 30 um around EC for the nearest macrophages + finds what total\n",
    "    # macrophage area is around the EC (approximation to the number of macrophages within the radius)\n",
    "    # it also creates a randomised mask of fake 'macrophages' and does the analysis with them as a randomised\n",
    "    # control to compare\n",
    "\n",
    "    labelled_647 = label(thresholded_647)\n",
    "    objects_647 = regionprops(labelled_647,img_647)\n",
    "    num_EC_cells = labelled_647.max()\n",
    "\n",
    "    watersheded_488 = watershed_488(thresholded_488, pixel_size)\n",
    "    objects_488 = regionprops(watersheded_488,img)\n",
    "    num_macrophages = watersheded_488.max()\n",
    "\n",
    "    # fake mac mask created:\n",
    "    fake_mac_mask = fake_mac_analysis(thresholded_405, num_macrophages, mac_rad)\n",
    "    labels_fake_mac = label(fake_mac_mask)\n",
    "    objects_fake_488 = regionprops(labels_fake_mac)\n",
    "\n",
    "    ## Start of distance analysis\n",
    "\n",
    "    #this is for the real data:\n",
    "    original_areas = []\n",
    "    sphericity = []\n",
    "    nearest_distances = []\n",
    "    mac_area_around_EC = []\n",
    "    mac_nb_around_EC = []\n",
    "    # this is for the randomised control:\n",
    "    random_nearest_distances = []\n",
    "    random_mac_area_around_EC = []\n",
    "    random_mac_nb_around_EC = []\n",
    "\n",
    "    for obj in objects_647:\n",
    "        obj_mask = np.zeros_like(thresholded_488, dtype=bool)\n",
    "        obj_mask[tuple(obj.coords.T)] = True\n",
    "\n",
    "        original_area = obj.area*(pixel_size**2)\n",
    "        original_areas.append(original_area)\n",
    "\n",
    "        sphericity.append(obj.eccentricity)\n",
    "\n",
    "        ## this is for the real data:\n",
    "        #nearest distance:\n",
    "        if np.any(obj_mask & (thresholded_488)):\n",
    "            nearest_distances.append(0)\n",
    "        else:\n",
    "            for i in range(1, number_of_iter + 1):\n",
    "                dilated_obj = binary_dilation(obj_mask, iterations=i)\n",
    "                if np.any(dilated_obj & thresholded_488):\n",
    "                    nearest_distances.append(i)\n",
    "                    break\n",
    "            else:\n",
    "                nearest_distances.append(number_of_iter+1)\n",
    "\n",
    "        #mac overlap:\n",
    "        dilated_obj_2 = binary_dilation(obj_mask.copy(), iterations=number_of_iter)\n",
    "        mac_area_in_radius = np.sum(thresholded_488 & dilated_obj_2)\n",
    "        mac_area_around_EC.append(mac_area_in_radius*(pixel_size**2))\n",
    "\n",
    "        overlapping_macs = 0\n",
    "        for object in objects_488:\n",
    "            coords = object.coords\n",
    "            if np.any(dilated_obj_2[coords[:,0], coords[:,1]]):\n",
    "                overlapping_macs += 1\n",
    "\n",
    "        mac_nb_around_EC.append(overlapping_macs)\n",
    "\n",
    "        ##this is for randomised control:\n",
    "        if np.any(obj_mask & (fake_mac_mask)):\n",
    "            random_nearest_distances.append(0)\n",
    "        else:\n",
    "            for i in range(1, number_of_iter + 1):\n",
    "                dilated_obj = binary_dilation(obj_mask, iterations=i)\n",
    "                if np.any(dilated_obj & fake_mac_mask):\n",
    "                    random_nearest_distances.append(i)\n",
    "                    break\n",
    "            else:\n",
    "                random_nearest_distances.append(number_of_iter+1)\n",
    "\n",
    "        #mac overlap:\n",
    "        random_mac_area_in_radius = np.sum(fake_mac_mask & dilated_obj_2)\n",
    "        random_mac_area_around_EC.append(random_mac_area_in_radius*(pixel_size**2))\n",
    "\n",
    "        overlapping_fake_macs = 0\n",
    "        for object in objects_fake_488:\n",
    "            coords = object.coords\n",
    "            if np.any(dilated_obj_2[coords[:,0], coords[:,1]]):\n",
    "                overlapping_fake_macs += 1\n",
    "\n",
    "        random_mac_nb_around_EC.append(overlapping_fake_macs)\n",
    "    \n",
    "\n",
    "    # percentage of ECs without a macrophage in 30um radius around them\n",
    "    per_of_unmac_ECs = (nearest_distances.count(number_of_iter + 1)/num_EC_cells if num_EC_cells > 0 else 0.0)\n",
    "    per_of_unmac_ECs_ctrl = (random_nearest_distances.count(number_of_iter + 1)/num_EC_cells if num_EC_cells > 0 else 0.0)\n",
    "    # average area of macs that can be found within 30um radius around EC in um^2\n",
    "    average_mac_area = mean(mac_area_around_EC) if mac_area_around_EC else 0\n",
    "    average_mac_area_ctrl = mean(random_mac_area_around_EC) if random_mac_area_around_EC else 0\n",
    "    # average EC area in um\n",
    "    average_EC_area = mean(original_areas) if original_areas else 0\n",
    "    # sphericity\n",
    "    average_EC_sphericity = mean(sphericity) if sphericity else None\n",
    "    # what is says, nearest distance from EC to macrophage in um\n",
    "    nearest_dist_um = [d * pixel_size for d in nearest_distances]\n",
    "    random_nearest_dist_um = [d * pixel_size for d in random_nearest_distances]\n",
    "    # average distance to the nearest macrophage in um\n",
    "    average_min_dist = mean(nearest_dist_um) if nearest_dist_um else 0\n",
    "    average_min_dist_ctrl = mean(random_nearest_dist_um) if random_nearest_dist_um else 0\n",
    "\n",
    "    # Distances mask:\n",
    "    expanded_ECs = binary_dilation(thresholded_647, iterations=number_of_iter)\n",
    "    mask_outline = find_boundaries(expanded_ECs)\n",
    "    thick_outline = binary_dilation(mask_outline, disk(2))\n",
    "\n",
    "    # Notification in the output if image doesn't have ECs:\n",
    "    if num_EC_cells == 0:\n",
    "        print(f\"{name_without_last_part} doesn't have any ECs\")\n",
    "\n",
    "    # image mask:\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Show background image\n",
    "    ax.imshow(thresholded_405, cmap='gray')\n",
    "    # Overlay cTnT in magenta\n",
    "    ax.imshow(np.ma.masked_where(myocardium == 0, myocardium), cmap='magma', alpha=0.4)\n",
    "    # Overlay macrophages in green\n",
    "    ax.imshow(np.ma.masked_where(thresholded_488 == 0, thresholded_488), cmap='Greens', vmin=0, vmax=1, alpha=0.9)\n",
    "    # Overlay ECS in red\n",
    "    ax.imshow(np.ma.masked_where(thresholded_647 == 0, thresholded_647), cmap='autumn', alpha=0.8)\n",
    "    # Nuclei\n",
    "    ax.imshow(np.ma.masked_where(mask_405 == 0, mask_405), cmap='Blues', vmin=0, vmax=1, alpha=0.8)\n",
    "\n",
    "    ax.set_title(f\"Channel masks for image: {name_without_last_part}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{folder1}/{name_without_last_part}.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    # image mask distances:\n",
    "    fig2, ax2 = plt.subplots(figsize=(8, 8))\n",
    "    ax2.imshow(thresholded_405, cmap='gray')\n",
    "    ax2.imshow(np.ma.masked_where(myocardium == 0, myocardium), cmap='magma', alpha=0.4)\n",
    "    ax2.imshow(np.ma.masked_where(thresholded_488 == 0, thresholded_488), cmap='Greens', vmin=0, vmax=1, alpha=0.9)\n",
    "    ax2.imshow(np.ma.masked_where(thresholded_647 == 0, thresholded_647), cmap='autumn', alpha=0.8)\n",
    "    ax2.imshow(np.ma.masked_where(thick_outline == 0, thick_outline), cmap='grey', alpha=0.9)\n",
    "    ax2.set_title(f\"Channel masks for image: {name_without_last_part}\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{folder1}/{name_without_last_part}_distances.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig2)\n",
    "\n",
    "    # image mask fake macs:\n",
    "    plt.imshow(fake_mac_mask)\n",
    "    plt.savefig(f\"{folder1}/{name_without_last_part}_fake_macs.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    # image data\n",
    "    Image_data_EC_files[name_without_last_part] = {\n",
    "        'organoid area [px^2]': organoid_size,\n",
    "        'organoid area [um^2]': organoid_size_in_um,\n",
    "        'number of nuclei': number_of_nuclei,\n",
    "        'average nuclei size [um^2]': mean(nuclei_sizes_in_um),\n",
    "        'nuclei sizes stdev': stdev(nuclei_sizes_in_um),\n",
    "        'myocardium area [px^2]': myocardium_area,\n",
    "        'myocardium area [um^2]': myocardium_area_in_um,\n",
    "        'myocardium area [%]': cTnT_per,\n",
    "        'myocardium nuclei': nuclei_count_myo,\n",
    "        'myocardium nuclei [%]': per_of_myo_nuclei,\n",
    "        'epicardium area [px^2]': epicardium_size,\n",
    "        'epicardium area [um^2]': epicardium_size_in_um,\n",
    "        'epicardium area [%]': epicardium_area_per,\n",
    "        'epicardium nuclei': nuclei_count_epi,\n",
    "        'epicardium nuclei [%]': per_of_epi_nuclei,\n",
    "        'EC area [um^2]': EC_signal_in_um,\n",
    "        'GFP area [um^2]': mac_signal_in_um,\n",
    "        'macs in epicardium [%]': GFP_per_in_epicardium,\n",
    "        'macs in myocardium [%]': GFP_per_in_myocardium,\n",
    "        'EC in epicardium [%]': EC_per_in_epicardium,\n",
    "        'EC in myocardium [%]': EC_per_in_myocardium,\n",
    "        'EC per nucleus count': EC_area_per_nuclei,\n",
    "        'macs per nucleus count': macs_area_per_nuclei,\n",
    "        'EC in epi per nuclei': EC_in_epi_per_nuclei,\n",
    "        'EC in myo per nuclei': EC_in_myo_per_nuclei,\n",
    "        'macs in epi per nuclei': GFP_in_epi_per_nuclei,\n",
    "        'macs in myo per nuclei': GFP_in_myo_per_nuclei,\n",
    "\n",
    "        # individual ECs:\n",
    "        'EC number': num_EC_cells,\n",
    "        'EC average area': average_EC_area,\n",
    "        'EC average spericity': average_EC_sphericity,\n",
    "        'Mac number': num_macrophages,\n",
    "        'EC w/o mac [%]': per_of_unmac_ECs,\n",
    "        'EC w/o mac ctrl [%]': per_of_unmac_ECs_ctrl,\n",
    "        'Average min distance [um]': average_min_dist,\n",
    "        'Average min distance ctrl [um]': average_min_dist_ctrl,\n",
    "        'Average mac area in radius [um^2]': average_mac_area,\n",
    "        'Average mac area in radius ctrl [um^2]': average_mac_area_ctrl,\n",
    "        'Average mac number in radius': mean(mac_nb_around_EC) if mac_nb_around_EC else 0,\n",
    "        'Average mac number in radius ctrl': mean(random_mac_nb_around_EC) if random_mac_nb_around_EC else 0\n",
    "\n",
    "    }\n",
    "\n",
    "    Individual_data_EC_files[name_without_last_part] = {\n",
    "        'EC areas': original_areas,\n",
    "        'EC sphericity': sphericity,\n",
    "        'Minimal distances': nearest_dist_um,\n",
    "        'Minimal distances ctrl': random_nearest_dist_um,\n",
    "        'Mac area in radius': mac_area_around_EC,\n",
    "        'Mac area in radius ctrl': random_mac_area_around_EC,\n",
    "        'Mac nb in radius': mac_nb_around_EC,\n",
    "        'Mac nb in radius ctrl': random_mac_nb_around_EC\n",
    "    }\n",
    "\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ec0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DATAFRAME\n",
    "df_stain1 = pd.DataFrame.from_dict(Image_data_EC_files, orient='index')\n",
    "output_path = f'{output_folder}/{last_folder}.xlsx' # this is the location+name of the output excel\n",
    "df_stain1.to_excel(output_path)\n",
    "\n",
    "# distances:\n",
    "output_path_2 = f'{output_folder}/{last_folder}_individual_distnaces.xlsx' #this is the location+name of the output excel distances\n",
    "dfs = []\n",
    "for name, data in Individual_data_EC_files.items():\n",
    "    max_len = max(len(v) for v in data.values())\n",
    "    df_img = pd.DataFrame({k: pd.Series(v) for k, v in data.items()})\n",
    "    df_img[\"Image\"] = name\n",
    "    dfs.append(df_img)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "cols = [\"Image\"] + [c for c in df_all.columns if c != \"Image\"]\n",
    "df_all = df_all[cols]\n",
    "df_all.to_excel(output_path_2, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
